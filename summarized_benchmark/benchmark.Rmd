---
title: "Benchmark De methods"
author: "Enrico Gaffo"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: yes
    toc_float: yes
    code_folding: hide
params:
  outdir: "DM1_benchmark_results"
  inputData: "./DM1_prep_ds/datasetList.qs"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(SummarizedBenchmark)
library("magrittr")
# library(plotROC)
library(data.table)
library(qs)
library(DT)

library("limma")
library("edgeR")
library("DESeq2")
library("tximport")
library(glmGamPoi)
library(zinbwave)
library(scran)

library(BiocParallel)
library(batchtools)

# install.packages("devtools", Ncpus = multicoreWorkers())
# library(devtools)
# install_github("lichen-lab/circMeta", Ncpus = multicoreWorkers())
library(circMeta)
# library(lncDIFF)
# library(ShrinkBayes)
# library(samr)
```

```{r}
## set the output directory
# outdir <- "benchmark_results"
outdir <- params$outdir
dir.create(path = outdir, recursive = T, showWarnings = F)
```

```{r}
nWorkers <- multicoreWorkers()

## load simulated preprocessed data
# inputData <- "./preprocessed_datasets/datasetList.qs"
inputData <- params$inputData
datasetList <- qread(file = inputData, nthreads = nWorkers)
```

```{r}
## separate DE and not-DE simulations
# datasetList <- datasetList[!grepl("mock", names(datasetList))]
## names(de_ds_list) <- paste0(names(de_ds_list), "_de")
# not_de_ds_list <- sim_ds_list[grepl("mock", names(sim_ds_list))]
```

# Prepare dataset and input parameters

## Weight functions

```{r}
compute_weights <- function(countdata, coldat, ...) {
  
  computeExactWeights <- function (model, x) {
    library(zinbwave)
    
    mu <- getMu(model)
    pi <- getPi(model)
    theta <- getTheta(model)
    theta <- matrix(rep(theta, each = ncol(x)), ncol = nrow(x))
    nb_part <- dnbinom(t(x), size = theta, mu = mu)
    zinb_part <- pi * ( t(x) == 0 ) + (1 - pi) *  nb_part
    zinbwg <- ( (1 - pi) * nb_part ) / zinb_part
    zinbwg <- t(zinbwg)
    zinbwg[x > 0] <- 1
    zinbwg[zinbwg < 1e-15] <- 1e-15
    zinbwg
  }
  
  library(zinbwave)
  
  zinbmodel <- zinbFit(Y = countdata,
                       X = model.matrix(~ coldat), 
                       K = 0,
                       # epsilon = nrow(countdata), #1e10
                       commondispersion = TRUE, 
                       verbose = FALSE, 
                       ...) #BPPARAM = BiocParallel::SerialParam()
  
  computeExactWeights(model = zinbmodel,
                      x = countdata)
}
```

```{r}
# subsetIdx <- c(1:3, 31:33, 61:63, # { bulk 3, 5, 10 } x 3
#                91:93, 121:123, 151:153) # { sice 3, 5, 10 } x 3
# subsetIdx <- c(1:2, 31:32, 61:62, 91:92, 121:122, 151:152)
# subsetIdx <- 1:2
subsetIdx <- 1:length(datasetList) # all
datasetList <- datasetList[subsetIdx]
```

```{r}
## set scheduler for cluster computing
zwcpus <- 8
bpparam <- BatchtoolsParam(workers = length(datasetList), 
                           saveregistry = F,
                           cluster = "slurm",
                           resources = list(ncpus = zwcpus, 
                                            walltime = 7200, # 2h max
                                            memory = 8192) # 4Gb, 2048 2GByte, 8192 8Gb
)

## Multithread, single machine
# bpparam <- MulticoreParam(nWorkers)
```

## Compute weigths

```{r prepare_datasets}
## prepare dataset and input parameters
datasetList <- 
  bplapply(datasetList, 
           function(x, compute_weights, zwcpus) {
             
             ## keep track of runtime spent computing weights with ZinbWave; 
             ## it will be sum up to the running time of methods using weights
             tictoc::tic(msg = "Weights")
             weights <- compute_weights(countdata = x$cntdat,
                                        coldat = x$coldat[[1]],
                                        BPPARAM = BiocParallel::MulticoreParam(workers = zwcpus))
             # weights = NULL, ## only for quick testing. Uncomment above for real weights
             time_weights <- tictoc::toc(log = F, quiet = T)
             
             x$weights <- weights
             x$time_weights <- setNames(rep(time_weights$toc - time_weights$tic, nrow(x$cntdat)), NULL)
             x
             
           }, 
           compute_weights = compute_weights,
           zwcpus = zwcpus,
           BPPARAM = bpparam)
```

```{r save_datasets}
# ## save the processed data sets
# inputData <- "datasetList.qs"
# qsave(x = datasetList, 
#       file = inputData, 
#       nthreads = multicoreWorkers(), 
#       preset = "fast")
```

# Bench design

```{r}
bd <- BenchDesign()
```

## Methods

### DESeq2 family

```{r}
## DESeq2 family

## 1. DESeq2 defaults
deseq2_run <- function(countData, colData, design, contrast) {

  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  dds <- DESeq2::DESeq(dds)
  res <- DESeq2::results(dds, 
                 contrast = contrast, 
                 test = "Wald", 
                 independentFiltering = F)
  # or to shrink log fold changes association with condition:
  # lfcShrink(dds, coef="condition_trt_vs_untrt", type="apeglm")
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)

}

## 2. use LRT 
deseq2lrt_run <- function(countData, colData, design, contrast) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  dds <- DESeq2::DESeq(dds, 
               test = "LRT",
               reduced = ~ 1)
  
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 3. use betaPrior
deseq2bp_run <- function(countData, colData, design, contrast) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  dds <- DESeq2::DESeq(dds, 
               betaPrior = T)
  res <- DESeq2::results(dds, 
                         contrast = contrast, 
                         test = "Wald", 
                         independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 4. use recommended parameters for single-cell data
## https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#recommendations-for-single-cell-analysis
## Use test="LRT"
## useT=TRUE
## minmu=1e-6 The default setting of minmu was benchmarked on bulk RNA-seq and 
##            is not appropriate for single cell data when the expected count is 
##            often much less than 1
## minReplicatesForReplace=Inf. 
## setting sizeFactors from scran::computeSumFactors. The default size factors 
##         are not optimal for single cell count matrices
## set fitType = "glmGamPoi"
deseq2zi_run <- function(countData, colData, design, contrast) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  
  dds <- DESeq2::DESeq(dds, 
                       # quiet = TRUE, 
                       sfType = "poscounts", 
                       useT = TRUE, 
                       minmu = 1e-6, 
                       minReplicatesForReplace = Inf, 
                       test = "LRT", 
                       reduced = ~ 1)
  # DESeq2::results(dds, contrast = contrast)
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 5. use recommended parameters for single-cell data and the genefilter::shorth
## in estimating  the size factors (parameter 'locfunc')
## ?estimateSizeFactors
## locfunc: a function to compute a location for a sample. By default, the 
##          median is used. However, especially for low counts, the shorth 
##          function from the genefilter package may give better results.
deseq2lc_run <- function(countData, colData, design, contrast) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  
  dds <- DESeq2::estimateSizeFactors(dds, type = "poscounts", 
                                     locfunc = function(x){ 
                                       tryCatch(
                                         {
                                           genefilter::shorth(x)
                                         },
                                         error = function(cond) {
                                           warning(paste("The 'shorth' function failed with the following message:\n", 
                                                         cond, 
                                                         "Will try to use 'half.range.mode' instead"))
                                           genefilter::half.range.mode(x)}
                                       ) })
  
  dds <- DESeq2::DESeq(dds, 
                       # quiet = TRUE, 
                       # sfType = "poscounts", 
                       useT = TRUE, 
                       minmu = 1e-6, 
                       minReplicatesForReplace = Inf, 
                       test = "LRT", 
                       reduced = ~ 1)
  # results(dds, contrast = contrast)
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 6. use recommended parameters for single-cell data and the scran::computeSumFactors
## to estimate the size factors
## 'setting sizeFactors from scran::computeSumFactors. The default size factors 
##  are not optimal for single cell count matrices'
deseq2sc_run <- function(countData, colData, design, contrast) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  
  # "sizeFactors"(dds) <- 
  #   DESeq2::sizeFactors(scran::computeSumFactors(dds, 
  #                                                clusters = SummarizedExperiment::colData(dds)$condition))
  dds <- scran::computeSumFactors(dds, 
                                  clusters = SummarizedExperiment::colData(dds)$condition)
  
  dds <- DESeq2::DESeq(dds, 
                       # quiet = TRUE, 
                       useT = TRUE, 
                       minmu = 1e-6, 
                       minReplicatesForReplace = Inf, 
                       test = "LRT", 
                       reduced = ~ 1)
  # DESeq2::results(dds, contrast = contrast)
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 7. By using the argument fitType="glmGamPoi", one can leverage the faster NB GLM 
## engine written by Constantin Ahlmann-Eltze. Note that glmGamPoi’s interface in 
## DESeq2 requires use of test="LRT" and specification of a reduced design.
## https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#speed-up-and-parallelization-thoughts
deseq2gpLrt_run <- function(countData, colData, design, contrast) {
  
  library(glmGamPoi)
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  
  dds <- DESeq2::DESeq(dds, 
                       # quiet = TRUE, 
                       sfType = "poscounts", 
                       # useT = TRUE, 
                       minmu = 1e-6, 
                       minReplicatesForReplace = Inf, 
                       fitType = "glmGamPoi",
                       test = "LRT", 
                       reduced = ~ 1)
  # DESeq2::results(dds, contrast = contrast)
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 8. use ZinbWave weights
deseq2zw_run <- function(countData, colData, design, contrast, weights) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  
  # if(is.null(weights)){
  #   message("Weights expected but NULL was given. DESeq2 will not use weights")
  # }else{
  #   weights[which(weights < 1e-6)] <- 1e-06
  #   assays(dds, withDimnames =F, "weights")[["weights"]] <- weights
  # }
  
  dds <- DESeq2::DESeq(dds, 
                       # quiet = TRUE, 
                       sfType = "poscounts", 
                       # useT = TRUE, 
                       minmu = 1e-6, 
                       minReplicatesForReplace = Inf, 
                       test = "LRT", 
                       reduced = ~ 1)
  # DESeq2::results(dds, contrast = contrast)
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## post functions
deseq2_pv <- function(x) { 
  res <- x$res$pvalue 
  res[is.na(res)] <- 1
  res
}

deseq2_apv <- function(x) { 
  res <- x$res$padj
  res[is.na(res)] <- 1
  res
}

deseq2_lfc <- function(x) { x$res$log2FoldChange }

deseq2_time <- function(x) { rep(as.numeric(x$runtime), nrow(x$res)) }
```

### edgeR family

```{r}
## edgeR family

## 1. default edgeR
edgeR_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y) # method = "TMMwsp" for zero counts?
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateDisp(y, des) # min.row.sum = 5 default. Change?
  fit <- edgeR::glmFit(y, des)
  res <- edgeR::glmLRT(fit, coef=2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 2. robust
edgeRrbst_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y) # method = "TMMwsp" for zero counts?
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateGLMRobustDisp(y, des) #maxit = 6
  fit <- edgeR::glmQLFit(y = y, 
                         dispersion = y$tagwise.dispersion, 
                         robust = TRUE, 
                         design = des)
  res <- edgeR::glmLRT(fit, coef = 2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 3. 50 degrees of freedom
## https://support.bioconductor.org/p/84338/
edgeRrbst50df_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y) # method = "TMMwsp" for zero counts?
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateGLMRobustDisp(y = y, des, prior.df = 50) #maxit = 6
  fit <- edgeR::glmQLFit(y = y, 
                         dispersion = y$tagwise.dispersion, 
                         robust = TRUE, 
                         design = des)
  res <- edgeR::glmLRT(fit, coef = 2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 4. auto estimation of df
edgeRrbstEdf_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y) # method = "TMMwsp" for zero counts?
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateDisp(y, des) #maxit = 6
  fit <- edgeR::glmQLFit(y = y, 
                         dispersion = y$tagwise.dispersion, 
                         robust = TRUE, 
                         design = des)
  res <- edgeR::glmLRT(fit, coef = 2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 5. ZinbWave weights
edgeRzw_run <- function(countData, group, design, weights) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y$weights <- weights
  y <- edgeR::calcNormFactors(y) # method = "TMMwsp" for zero counts?
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateGLMRobustDisp(y, des) # estimateDisp(y, des)?
  fit <- edgeR::glmFit(y, des) #glmQLFit?
  res <- edgeR::glmLRT(fit, coef = 2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 6. Quasi-likelihood dispersion estimate and empirical Bayes quasi-likelihood F-tests
## glmQLFit gives special attention to handling of zero counts
## https://support.bioconductor.org/p/84338/
## and
## https://support.bioconductor.org/p/84291/#84292
## "There are some situations where the QL F-test doesn't work well - for example, [...]
## where the dispersions are very large and the counts are very small, whereby 
## some of the approximations in the QL framework seem to fail. In such cases, 
## I usually switch to the LRT rather than using the exact test, for the reasons 
## of experimental flexibility that I mentioned above."
edgeRql_run <- function(countData, group, design, weights) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y) # method = "TMMwsp" for zero counts?
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateDisp(y = y, design = des, robust = TRUE)
  fit <- edgeR::glmQLFit(y, design = des, robust = TRUE)
  res <- edgeR::glmQLFTest(fit, coef = 2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## post functions
edgeR_pv <- function(x) { 
  res <- x$res$table$PValue 
  res[is.na(res)] <- 1
  res
}

edgeR_apv <- function(x) {
  res <- p.adjust(p = x$res$table$PValue, method = "BH")
  # res <- topTags(x, number = Inf, sort.by = "none")$table$FDR
  res[is.na(res)] <- 1
  res
}

edgeR_lfc <- function(x) { x$res$table$logFC }

edgeR_time <- function(x) { rep(as.numeric(x$runtime), nrow(x$res)) }
```

### limma-voom family

```{r}
## limma-voom family
voom_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y)
  des <- model.matrix(design)
  y <- limma::voom(y, des)
  res <- limma::eBayes(limma::lmFit(y, des))
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## estimation of df.prior and var.prior be robustified against outlier sample variances
voomRbst_run <- function(countData, group, design) {

  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y) # method = "TMMwsp" for zero counts?
  des <- model.matrix(design)
  y <- limma::voom(y, des)
  res <- limma::eBayes(limma::lmFit(y, des), 
                       robust = T)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## voom quantile normalization
voomQn_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  des <- model.matrix(design)
  voom.data <- limma::voom(countData, 
                           design = des, 
                           normalize.method = 'quantile')
  #"none", "scale", "quantile" or "cyclicloess
  res <- limma::eBayes(limma::lmFit(voom.data, design = des))
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## limma-voom code as in the vignette (no prior edgeR; mind the robust = T param)
voomSimple_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  des <- model.matrix(design)
  res <- limma::eBayes(limma::lmFit(limma::voom(counts = countData, 
                                                design = des), 
                                    des), 
                       robust = TRUE)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}


## voomLmFit is more robust to zero counts than calling voom, 
## duplicateCorrelation and lmFit separately and provides more 
## rigorous error rate control.
## ?limma::voom
## Note that edgeR::voomLmFit is now recommended over voom for 
## sparse counts with a medium to high proportion of zeros.
voomLmFit_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  des <- model.matrix(design)
  ## Empirical sample quality weights will be estimated if sample.weights=TRUE 
  ## or if var.design or var.group are non-NULL. In that case, voomLmFit is 
  ## analogous to running voomWithQualityWeights followed by lmFit.
  ## voomLmFit is usually followed by running eBayes on the fitted model object. 
  res <- limma::eBayes(edgeR::voomLmFit(counts = countData, 
                                        design = des, 
                                        # block = NULL, 
                                        # prior.weights = NULL,
                                        sample.weights = TRUE,
                                        # var.design = NULL, 
                                        # var.group = NULL, 
                                        # lib.size = NULL, 
                                        # normalize.method = "none",
                                        # span = 0.5, 
                                        # plot = FALSE, 
                                        save.plot = FALSE))
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

# limma-voom with ZINBWaVE weights
voomZw_run <- function(countData, group, design, weights) {
  
  tictoc::tic()
  
  des <- model.matrix(design)
  v <- limma::voom(counts = countData, 
                   design = des, 
                   plot = FALSE, 
                   weights = weights)
  # v$weights <- v$weights * weights
  fit <- limma::lmFit(v, design = des, weights = v$weights)
  # fit$df.residual <- rowSums(weights) - ncol(design)
  res <- limma::eBayes(fit, robust = T)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

# voomWithQualityWeights

## post functions
voom_pv <- function(x) { 
  res <- x$res$p.value[, 2] # res <- x$F.p.value	?
  res[is.na(res)] <- 1
  res
}

voom_apv <- function(x) {
  # res <- p.adjust(p = x$p.value[, 2], method = "BH")
  res <- limma::topTable(x$res, number = Inf, sort.by = "none")$adj.P.Val
  res[is.na(res)] <- 1
  res
}

voom_lfc <- function(x) {
  # x$coefficients[, 2]
  limma::topTable(x$res, number = Inf, sort.by = "none")$logFC
}

voom_time <- function(x) { rep(as.numeric(x$runtime), nrow(x$res)) }
```

### circMeta

```{r}
## circMeta
cMeta_run <- function(countData, group, sf = TRUE) {
  
  tictoc::tic()
  
  groupVar <- group 
  names(groupVar) <- colnames(countData)
  countData <- apply(countData, 2, function(x) {storage.mode(x) <- 'integer'; x})
  m = rowMeans(countData)

  sfs = colSums(countData)
  sfs = sfs / min(sfs)
  if(sf) countData = sweep(countData, 2, sfs, FUN='/')
  n0 = sum(groupVar == levels(groupVar)[1]) 
  n1 = sum(groupVar == levels(groupVar)[2]) # assume 2 levels factor groups
  m0 = rowMeans(countData[, groupVar == levels(groupVar)[1]])
  m1 = rowMeans(countData[, groupVar == levels(groupVar)[2]])
  n  = nrow(countData)
  pval = rep(1, n)
  for(i in 1:n){
    z = (m1[i] - m0[i]) / sqrt(m1[i] / n1 + m0[i] / n0)
    pval[i] = 2 * pnorm(-abs(z))
  }
  
  # fdr = p.adjust(pval, method = 'fdr')
  lfc <- log( (m1 + 1) / (m0 + 1), 2)
  
  names(pval) <- rownames(countData)
  res <- data.frame(p.value = pval, 
                    logFC = lfc)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

cMetaLc_run <- function(countData, group, sf = TRUE) {
  
  tictoc::tic()
  
  groupVar <- group 
  names(groupVar) <- colnames(countData)
  countData <- apply(countData, 2, function(x) {storage.mode(x) <- 'integer'; x})
  m = rowMeans(countData)

  sfs = colSums(countData)
  sfs = sfs / min(sfs)
  if(sf) countData = sweep(countData, 2, sfs, FUN='/')
  n0 = sum(groupVar == levels(groupVar)[1]) 
  n1 = sum(groupVar == levels(groupVar)[2]) # assume 2 levels factor groups
  m0 = rowMeans(countData[, groupVar == levels(groupVar)[1]])
  m1 = rowMeans(countData[, groupVar == levels(groupVar)[2]])
  n  = nrow(countData)
  pval = rep(1, n)
  for(i in 1:n){
    z = ( sqrt(m1[i]) - sqrt(m0[i]) ) / (1 / 2 * sqrt(1 / n1 + 1 / n0))
    pval[i] = 2 * pnorm(-abs(z))
  }
  
  # fdr = p.adjust(pval, method = 'fdr')
  lfc <- log( (m1 + 1) / (m0 + 1), 2)
  
  names(pval) <- rownames(countData)
  res <- data.frame(p.value = pval, 
                    logFC = lfc)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## post functions
cMeta_pv <- function(x) { 
  res <- x$res$p.value
  res[is.na(res)] <- 1
  res
}

cMeta_apv <- function(x) {
  res <- p.adjust(x$res$p.value, method = "BH")
  res[is.na(res)] <- 1
  res
}

cMeta_lfc <- function(x) { x$res$logFC }

cMeta_time <- function(x) { rep(as.numeric(x$runtime), nrow(x$res)) }
```

## Add memthods to the bench

```{r}
## add memthods to the bench
bd <- bd %>%
  addMethod(label = "DESeq2_Dt_WaT", ## DESeq2, default parameters, Wald test
            func = deseq2_run, 
            # post = deseq2_pv,
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2", pkg_vers = as.character(packageVersion("DESeq2"))),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_Dt_LRT", ## DESeq2, default parameters, likelihood ratio test
            func = deseq2lrt_run, 
            # post = deseq2_pv,
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2", pkg_vers = as.character(packageVersion("DESeq2"))),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_Lc_LRT", ## DESeq2, parameters for low counts, likelihood ratio test
            func = deseq2lc_run, 
            # post = deseq2_pv,
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2", pkg_vers = as.character(packageVersion("DESeq2"))),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_Zi_LRT", ## DESeq2, parameters for single-cell data, likelihood ratio test
            func = deseq2zi_run, 
            # post = deseq2_pv, 
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2", pkg_vers = as.character(packageVersion("DESeq2"))),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_Sc_LRT", ## DESeq2, parameters for single-cell data and scran::computeSumFactors, likelihood ratio test
            func = deseq2sc_run, 
            # post = deseq2_pv,
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2/scran",
                        pkg_vers = paste(as.character(packageVersion("DESeq2")),
                                         as.character(packageVersion("scran")),
                                         sep = "/")),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat,
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_GP_LRT", ## DESeq2, Gamma-Poisson, likelihood ratio test
            func = deseq2gpLrt_run, 
            # post = deseq2_pv, 
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2/glmGamPoi", 
                        pkg_vers = paste(as.character(packageVersion("DESeq2")), 
                                         as.character(packageVersion("glmGamPoi")), 
                                         sep = "/")),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_ZW_LRT", ## DESeq2, ZinbWave, likelihood ratio test
            func = deseq2zw_run, 
            # post = deseq2_pv, 
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2/zinbwave", 
                        pkg_vers = paste(as.character(packageVersion("DESeq2")), 
                                         as.character(packageVersion("zinbwave")), 
                                         sep = "/")),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"),
                                 weights = weights)) %>%
  addMethod(label = "DESeq2_BP_WaT", ## DESeq2, betaPrior=T, Wald test
            func = deseq2bp_run, 
            # post = deseq2_pv,
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2", pkg_vers = as.character(packageVersion("DESeq2"))),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "edgeR_Dt_LRT", ## edgeR, defaults, likelihood ratio test 
            func = edgeR_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR", pkg_vers = as.character(packageVersion("edgeR"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
  addMethod(label = "edgeR_ZW_LRT", ## edgeR, ZinbWave, likelihood ratio test 
            func = edgeRzw_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR/zinbwave", 
                        pkg_vers = paste(as.character(packageVersion("edgeR")), 
                                         as.character(packageVersion("zinbwave")), 
                                         sep = "/")),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition,
                                 weights = weights)) %>%
  addMethod(label = "edgeR_rbst_LRT", ## edgeR, robust dispersion estimate, likelihood ratio test 
            func = edgeRrbst_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR", pkg_vers = as.character(packageVersion("edgeR"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
  addMethod(label = "edgeR_rbst50df_LRT", ## edgeR, robust dispersion estimate with 50 degrees of freedom, likelihood ratio test 
            func = edgeRrbst50df_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR", pkg_vers = as.character(packageVersion("edgeR"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
  addMethod(label = "edgeR_rbstEdf_LRT", ## edgeR, robust dispersion estimate with autodetermied number of degrees of freedom, likelihood ratio test 
            func = edgeRrbstEdf_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR", pkg_vers = as.character(packageVersion("edgeR"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
    addMethod(label = "edgeR_rbst_QFT", ## edgeR, robust dispersion estimate, empirical Bayes quasi-likelihood F-test 
            func = edgeRql_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR", pkg_vers = as.character(packageVersion("edgeR"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
  addMethod(label = "voom_Dt_MFT", ## limma-voom, defauls, moderated F-statistic (or is it t-stats ?) 
            func = voom_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom", pkg_vers = as.character(packageVersion("limma"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
    addMethod(label = "voom_Rb_MFT", ## limma-voom, use robust est, moderated F-statistic (or is it t-stats ?) 
            func = voomRbst_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom", pkg_vers = as.character(packageVersion("limma"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
    addMethod(label = "voom_Qn_MFT", ## limma-voom, use quantile normalization, moderated F-statistic (or is it t-stats ?) 
            func = voomQn_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom", pkg_vers = as.character(packageVersion("limma"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
    addMethod(label = "voom_Sp_MFT", ## limma-voom, defaults as in vignette, moderated F-statistic (or is it t-stats ?) 
            func = voomSimple_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom", pkg_vers = as.character(packageVersion("limma"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
    addMethod(label = "voom_LF_MFT", ## limma-voom, use voomLmFit, moderated F-statistic (or is it t-stats ?) 
            func = voomLmFit_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom", pkg_vers = as.character(packageVersion("limma"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
  addMethod(label = "voom_ZW_MFT", ## limma-voom, use ZinbWave weigths, moderated F-statistic (or is it t-stats ?) 
            func = voomZw_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom/zinbwave", 
                        pkg_vers = paste(as.character(packageVersion("limma")), 
                                         as.character(packageVersion("zinbwave")), 
                                         sep = "/")),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition,
                                 weights = weights)) %>%
  addMethod(label = "circMeta_Dt_PZT", ## circMeta, defaults, Poisson z-test
            func = cMeta_run, 
            post = list(pv = cMeta_pv,
                        adj_pv = cMeta_apv,
                        lfc = cMeta_lfc,
                        runtime = cMeta_time),
            meta = list(pkg_name = "circMeta", pkg_vers = as.character(packageVersion("circMeta"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition)) %>%
  addMethod(label = "circMeta_Lc_PZT", ## circMeta, sqrt of counts, Poisson z-test
            func = cMetaLc_run, 
            post = list(pv = cMeta_pv,
                        adj_pv = cMeta_apv,
                        lfc = cMeta_lfc,
                        runtime = cMeta_time),
            meta = list(pkg_name = "circMeta", pkg_vers = as.character(packageVersion("circMeta"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition)) #%>%
  # addMethod(label = "lncDIFF_Dt_LRT", ## lncDIFF, defaults, test?
  #           func = lncdiff_run, 
  #           post = list(pv = lncdiff_pv,
  #                       adj_pv = lncdiff_apv,
  #                       lfc = lncdiff_lfc,
  #                       runtime = lncdiff_time),
  #           meta = list(pkg_name = "lncDIFF", pkg_vers = as.character(packageVersion("lncDIFF"))),
  #           params = rlang::quos(countData = cntdat,
  #                                group = coldat$condition)) %>%
  # addMethod(label = "SAMseq_Dt_TT", ## lncDIFF, defaults, test?
  #           func = samseq_run, 
  #           post = list(pv = samseq_pv,
  #                       adj_pv = samseq_apv,
  #                       lfc = samseq_lfc,
  #                       runtime = samseq_time),
  #           meta = list(pkg_name = "samr", pkg_vers = as.character(packageVersion("samr"))),
  #           params = rlang::quos(countData = cntdat,
  #                                group = coldat$condition))

bd
```

```{r}
printMethods(bd)
```

## Build bench list

```{r build_benches}
## override BPPARAM
parallel_methods <- 4
bpparam$resources$ncpus <- parallel_methods

sbL <- 
  bplapply(datasetList, 
           function(x, bd, parallel_methods) { 
             SummarizedBenchmark::buildBench(bd, data = x, 
                                             truthCols = c(pv = "status",
                                                           adj_pv = "status", 
                                                           lfc = "status", # LFC(DEC) >= 0.5
                                                           runtime = "time_weights"), 
                                             keepData = T,
                                             parallel = T, 
                                             BPPARAM = BiocParallel::MulticoreParam(parallel_methods)) 
           }, 
           bd = bd,
           parallel_methods = parallel_methods,
           BPPARAM = bpparam)
# sbL
```

```{r}
## error handling
show_dt <- 
  dcast(melt(rbindlist(lapply(sbL, 
                              function(x)data.table(as.data.frame(simplify2array(metadata(x)$sessions[[1]]$results)), 
                                                    keep.rownames = "Assay")), 
                       idcol = "DS"), 
             id.vars = c("DS", "Assay"), 
             variable.name = "Method"), 
        formula = DS + Method ~ Assay)

show_dt$DS <- factor(show_dt$DS)
show_dt$Method <- factor(show_dt$Method)

datatable(show_dt[adj_pv != "success" | 
                    lfc != "success" | 
                    pv != "success" | 
                    runtime != "success"], 
          caption = "Methods that failed",
          filter = "top", rownames = F)
```

```{r}
## save the summarizedBenchmark builds
sumBenchs_qs <- file.path(outdir, "sumBenchs.qs")
qsave(x = sbL, 
      file = sumBenchs_qs, 
      nthreads = multicoreWorkers(), 
      preset = "fast")
```

The built SummarizedBenchmark objects have been save into <a href="`r sumBenchs_qs`">`r sumBenchs_qs`</a>.  

# Performance

```{r}
# availableMetrics()
```

## Add performance 

```{r}
#' Adds performance metrics to a SummarizedBenchmark object
#' param x the SummarizedBenchmark object
#' returns a SummarizedBenchmark with the peformance metrics setted
add_performance_metrics <- 
  function(x) {
    
    ## Notes:
    ## precision (PPV) = 1 - FDR
    ## recall = TPR
    ## specificity = TNR  
    ## FPR = 1 - TNR
    ## FNR = 1 - TPR
    ## F1 = 2 * ( (PPV * TPR) / (PPV + TPR) )
    
    ## add the metrics on the P-values
    x <- SummarizedBenchmark::addPerformanceMetric(x, 
                                                   evalMetric = c("rejections", "TPR", "TNR", "FDR"), #, "FNR"
                                                   assay = "pv")
    
    ## add the metrics on the adjusted P-values
    x <- SummarizedBenchmark::addPerformanceMetric(x, 
                                                   evalMetric = c("rejections", "TPR", "TNR", "FDR"), #, "FNR"
                                                   assay = "adj_pv")
    
    ## add the metrics on the fold changes: TPR
    x <- SummarizedBenchmark::addPerformanceMetric(object = x,
                                                   assay = "lfc",
                                                   evalMetric = "LFC_TPR",
                                                   evalFunction = function(query, truth, lfc_thr = 0.5) {
                                                     ## TPR = TP / (TP + FN)
                                                     is_lfc_larger  <- query >= lfc_thr
                                                     is_lfc_larger[is.na(is_lfc_larger)] <- F
                                                     TP <- sum(is_lfc_larger & truth == 1)
                                                     TP / sum(truth == 1)
                                                   })
    
    ## add the metrics on the fold changes: TNR
    x <- SummarizedBenchmark::addPerformanceMetric(object = x,
                                                   assay = "lfc",
                                                   evalMetric = "LFC_TNR", 
                                                   evalFunction = function(query, truth, lfc_thr = 0.5) {
                                                     ## TNR = TN / N, with N = TN + FP
                                                     is_lfc_lower  <- query < lfc_thr
                                                     is_lfc_lower[is.na(is_lfc_lower)] <- T
                                                     TN <- sum(is_lfc_lower & truth == 0)
                                                     TN / sum(truth == 0)
                                                   })
    
    ## add the metrics on the fold changes: FDR
    x <- SummarizedBenchmark::addPerformanceMetric(object = x,
                                                   assay = "lfc",
                                                   evalMetric = "LFC_FDR", 
                                                   evalFunction = function(query, truth, lfc_thr = 0.5) {
                                                     ## FDR = FP / (FP + TP)
                                                     is_lfc_larger  <- query >= lfc_thr
                                                     is_lfc_larger[is.na(is_lfc_larger)] <- F
                                                     FP <- sum(is_lfc_larger & truth == 0)
                                                     TP <- sum(is_lfc_larger & truth == 1)
                                                     FP / (FP + TP)
                                                   })
    
    ## add the Runtime metric
    x <- SummarizedBenchmark::addPerformanceMetric(object = x,
                                                   assay = "runtime",
                                                   evalMetric = "Runtime",
                                                   evalFunction = function(query, truth, add_weight_time = FALSE) {
                                                     ifelse(add_weight_time, query[1] + truth[1], query[1])
                                                   })
    
    ## return the updated SummarizedBenchmark object
    x
  }
```

```{r add_performance_metrics}
## add the performance metrics to the list of bechDesign
bpparam$resources$ncpus <- 1

sbL <- 
  bplapply(sbL, 
           add_performance_metrics,
           BPPARAM = bpparam)
# BPPARAM = BiocParallel::MulticoreParam(nWorkers))
```

## Estimate performance

```{r estimate_performance}
alpha_targets <- c(0.01, 0.05, 0.1) 
add_weights <- c(FALSE, TRUE)

sbL <- bplapply(sbL, function(x, alphas, add_weights) {
  SummarizedBenchmark::estimatePerformanceMetrics(x, 
                                                  rerun = T,
                                                  alpha = alphas, 
                                                  add_weight_time = add_weights,
                                                  addColData = T)},
  alphas = alpha_targets,
  add_weights = add_weights,
  # BPPARAM = BiocParallel::MulticoreParam(nWorkers))
  BPPARAM = bpparam)

# View(rbindlist(lapply(sbL,
#                       function(x)data.table(as.data.frame(colData(x)),
#                                             keep.rownames = "Met")),
#                idcol = "DS"))
```

```{r save_performance_results}
## save the summarizedBenchmark estimated performance
sumBench_perf_metrics_qs <- file.path(outdir, "sumBench_perf_metrics.qs")
qsave(x = sbL, 
      file = sumBench_perf_metrics_qs, 
      nthreads = multicoreWorkers(), 
      preset = "fast")
```

The benchmark results have been save into <a href="`r sumBench_perf_metrics_qs`">`r sumBench_perf_metrics_qs`</a>.  

# Session info

```{r}
sessionInfo()
```

